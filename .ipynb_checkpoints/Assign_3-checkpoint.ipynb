{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MACHINE LEARNING ASSIGNMENT -3 ############\n",
    "### DECISION TREE, RANDOM FOREST, SUPPORT VECTOR CLASSIFICATION\n",
    "## IMPLEMENTATION USING SCI-KIT LEARN\n",
    "# Note : NOT FROM SCRATCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "from sklearn import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for i in range(0,60):\n",
    "    n.append(i)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 'o']\n"
     ]
    }
   ],
   "source": [
    "n.append(\"o\")\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sonar.all-data\" , names =n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "        9  ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  o  \n",
       "0  0.0090  0.0032  0  \n",
       "1  0.0052  0.0044  0  \n",
       "2  0.0095  0.0078  0  \n",
       "3  0.0040  0.0117  0  \n",
       "4  0.0107  0.0094  0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df[\"o\"].value_counts()\n",
    "repl = {\"o\": {\"M\": 1, \"R\": 0 }}\n",
    "df_new = df.replace(repl)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_new.drop(df.columns[len(df.columns)-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      50      51      52      53      54      55      56  \\\n",
       "0  0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1  0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2  0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3  0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4  0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "\n",
       "       57      58      59  \n",
       "0  0.0084  0.0090  0.0032  \n",
       "1  0.0049  0.0052  0.0044  \n",
       "2  0.0164  0.0095  0.0078  \n",
       "3  0.0044  0.0040  0.0117  \n",
       "4  0.0048  0.0107  0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0       1       2       3       4       5       6       7       8   \\\n",
      "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "5    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
      "6    0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
      "7    0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
      "8    0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
      "9    0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
      "10   0.0039  0.0063  0.0152  0.0336  0.0310  0.0284  0.0396  0.0272  0.0323   \n",
      "11   0.0123  0.0309  0.0169  0.0313  0.0358  0.0102  0.0182  0.0579  0.1122   \n",
      "12   0.0079  0.0086  0.0055  0.0250  0.0344  0.0546  0.0528  0.0958  0.1009   \n",
      "13   0.0090  0.0062  0.0253  0.0489  0.1197  0.1589  0.1392  0.0987  0.0955   \n",
      "14   0.0124  0.0433  0.0604  0.0449  0.0597  0.0355  0.0531  0.0343  0.1052   \n",
      "15   0.0298  0.0615  0.0650  0.0921  0.1615  0.2294  0.2176  0.2033  0.1459   \n",
      "16   0.0352  0.0116  0.0191  0.0469  0.0737  0.1185  0.1683  0.1541  0.1466   \n",
      "17   0.0192  0.0607  0.0378  0.0774  0.1388  0.0809  0.0568  0.0219  0.1037   \n",
      "18   0.0270  0.0092  0.0145  0.0278  0.0412  0.0757  0.1026  0.1138  0.0794   \n",
      "19   0.0126  0.0149  0.0641  0.1732  0.2565  0.2559  0.2947  0.4110  0.4983   \n",
      "20   0.0473  0.0509  0.0819  0.1252  0.1783  0.3070  0.3008  0.2362  0.3830   \n",
      "21   0.0664  0.0575  0.0842  0.0372  0.0458  0.0771  0.0771  0.1130  0.2353   \n",
      "22   0.0099  0.0484  0.0299  0.0297  0.0652  0.1077  0.2363  0.2385  0.0075   \n",
      "23   0.0115  0.0150  0.0136  0.0076  0.0211  0.1058  0.1023  0.0440  0.0931   \n",
      "24   0.0293  0.0644  0.0390  0.0173  0.0476  0.0816  0.0993  0.0315  0.0736   \n",
      "25   0.0201  0.0026  0.0138  0.0062  0.0133  0.0151  0.0541  0.0210  0.0505   \n",
      "26   0.0151  0.0320  0.0599  0.1050  0.1163  0.1734  0.1679  0.1119  0.0889   \n",
      "27   0.0177  0.0300  0.0288  0.0394  0.0630  0.0526  0.0688  0.0633  0.0624   \n",
      "28   0.0100  0.0275  0.0190  0.0371  0.0416  0.0201  0.0314  0.0651  0.1896   \n",
      "29   0.0189  0.0308  0.0197  0.0622  0.0080  0.0789  0.1440  0.1451  0.1789   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "178  0.0197  0.0394  0.0384  0.0076  0.0251  0.0629  0.0747  0.0578  0.1357   \n",
      "179  0.0394  0.0420  0.0446  0.0551  0.0597  0.1416  0.0956  0.0802  0.1618   \n",
      "180  0.0310  0.0221  0.0433  0.0191  0.0964  0.1827  0.1106  0.1702  0.2804   \n",
      "181  0.0423  0.0321  0.0709  0.0108  0.1070  0.0973  0.0961  0.1323  0.2462   \n",
      "182  0.0095  0.0308  0.0539  0.0411  0.0613  0.1039  0.1016  0.1394  0.2592   \n",
      "183  0.0096  0.0404  0.0682  0.0688  0.0887  0.0932  0.0955  0.2140  0.2546   \n",
      "184  0.0269  0.0383  0.0505  0.0707  0.1313  0.2103  0.2263  0.2524  0.3595   \n",
      "185  0.0340  0.0625  0.0381  0.0257  0.0441  0.1027  0.1287  0.1850  0.2647   \n",
      "186  0.0209  0.0191  0.0411  0.0321  0.0698  0.1579  0.1438  0.1402  0.3048   \n",
      "187  0.0368  0.0279  0.0103  0.0566  0.0759  0.0679  0.0970  0.1473  0.2164   \n",
      "188  0.0089  0.0274  0.0248  0.0237  0.0224  0.0845  0.1488  0.1224  0.1569   \n",
      "189  0.0158  0.0239  0.0150  0.0494  0.0988  0.1425  0.1463  0.1219  0.1697   \n",
      "190  0.0156  0.0210  0.0282  0.0596  0.0462  0.0779  0.1365  0.0780  0.1038   \n",
      "191  0.0315  0.0252  0.0167  0.0479  0.0902  0.1057  0.1024  0.1209  0.1241   \n",
      "192  0.0056  0.0267  0.0221  0.0561  0.0936  0.1146  0.0706  0.0996  0.1673   \n",
      "193  0.0203  0.0121  0.0380  0.0128  0.0537  0.0874  0.1021  0.0852  0.1136   \n",
      "194  0.0392  0.0108  0.0267  0.0257  0.0410  0.0491  0.1053  0.1690  0.2105   \n",
      "195  0.0129  0.0141  0.0309  0.0375  0.0767  0.0787  0.0662  0.1108  0.1777   \n",
      "196  0.0050  0.0017  0.0270  0.0450  0.0958  0.0830  0.0879  0.1220  0.1977   \n",
      "197  0.0366  0.0421  0.0504  0.0250  0.0596  0.0252  0.0958  0.0991  0.1419   \n",
      "198  0.0238  0.0318  0.0422  0.0399  0.0788  0.0766  0.0881  0.1143  0.1594   \n",
      "199  0.0116  0.0744  0.0367  0.0225  0.0076  0.0545  0.1110  0.1069  0.1708   \n",
      "200  0.0131  0.0387  0.0329  0.0078  0.0721  0.1341  0.1626  0.1902  0.2610   \n",
      "201  0.0335  0.0258  0.0398  0.0570  0.0529  0.1091  0.1709  0.1684  0.1865   \n",
      "202  0.0272  0.0378  0.0488  0.0848  0.1127  0.1103  0.1349  0.2337  0.3113   \n",
      "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
      "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
      "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
      "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
      "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
      "\n",
      "         9   ...      50      51      52      53      54      55      56  \\\n",
      "0    0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
      "1    0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
      "2    0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
      "3    0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
      "4    0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
      "5    0.3039  ...  0.0104  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057   \n",
      "6    0.3513  ...  0.0195  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092   \n",
      "7    0.2838  ...  0.0052  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085   \n",
      "8    0.1487  ...  0.0061  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065   \n",
      "9    0.0251  ...  0.0118  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032   \n",
      "10   0.0452  ...  0.0062  0.0062  0.0120  0.0052  0.0056  0.0093  0.0042   \n",
      "11   0.0835  ...  0.0188  0.0133  0.0265  0.0224  0.0074  0.0118  0.0026   \n",
      "12   0.1240  ...  0.0174  0.0176  0.0127  0.0088  0.0098  0.0019  0.0059   \n",
      "13   0.1895  ...  0.0187  0.0059  0.0095  0.0194  0.0080  0.0152  0.0158   \n",
      "14   0.2120  ...  0.0078  0.0083  0.0057  0.0174  0.0188  0.0054  0.0114   \n",
      "15   0.0852  ...  0.0154  0.0031  0.0153  0.0071  0.0212  0.0076  0.0152   \n",
      "16   0.2912  ...  0.0426  0.0346  0.0158  0.0154  0.0109  0.0048  0.0095   \n",
      "17   0.1186  ...  0.0360  0.0331  0.0131  0.0120  0.0108  0.0024  0.0045   \n",
      "18   0.1520  ...  0.0045  0.0084  0.0010  0.0018  0.0068  0.0039  0.0120   \n",
      "19   0.5920  ...  0.0153  0.0092  0.0035  0.0098  0.0121  0.0006  0.0181   \n",
      "20   0.3759  ...  0.0107  0.0193  0.0118  0.0064  0.0042  0.0054  0.0049   \n",
      "21   0.1838  ...  0.0135  0.0141  0.0190  0.0043  0.0036  0.0026  0.0024   \n",
      "22   0.1882  ...  0.0396  0.0173  0.0149  0.0115  0.0202  0.0139  0.0029   \n",
      "23   0.0734  ...  0.0107  0.0091  0.0016  0.0084  0.0064  0.0026  0.0029   \n",
      "24   0.0860  ...  0.0170  0.0035  0.0052  0.0083  0.0078  0.0075  0.0105   \n",
      "25   0.1097  ...  0.0072  0.0108  0.0070  0.0063  0.0030  0.0011  0.0007   \n",
      "26   0.1205  ...  0.0086  0.0061  0.0015  0.0084  0.0128  0.0054  0.0011   \n",
      "27   0.0613  ...  0.0168  0.0102  0.0122  0.0044  0.0075  0.0124  0.0099   \n",
      "28   0.2668  ...  0.0118  0.0088  0.0104  0.0036  0.0088  0.0047  0.0117   \n",
      "29   0.2522  ...  0.0091  0.0038  0.0096  0.0142  0.0190  0.0140  0.0099   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "178  0.1695  ...  0.0091  0.0134  0.0097  0.0042  0.0058  0.0072  0.0041   \n",
      "179  0.2558  ...  0.0118  0.0146  0.0040  0.0114  0.0032  0.0062  0.0101   \n",
      "180  0.4432  ...  0.0249  0.0204  0.0059  0.0053  0.0079  0.0037  0.0015   \n",
      "181  0.2696  ...  0.0367  0.0176  0.0035  0.0093  0.0121  0.0075  0.0056   \n",
      "182  0.3745  ...  0.0357  0.0181  0.0019  0.0102  0.0133  0.0040  0.0042   \n",
      "183  0.2952  ...  0.0310  0.0237  0.0078  0.0144  0.0170  0.0012  0.0109   \n",
      "184  0.5915  ...  0.0346  0.0167  0.0199  0.0145  0.0081  0.0045  0.0043   \n",
      "185  0.4117  ...  0.0329  0.0141  0.0019  0.0067  0.0099  0.0042  0.0057   \n",
      "186  0.3914  ...  0.0054  0.0078  0.0201  0.0104  0.0039  0.0031  0.0062   \n",
      "187  0.2544  ...  0.0151  0.0105  0.0024  0.0018  0.0057  0.0092  0.0009   \n",
      "188  0.2119  ...  0.0199  0.0096  0.0103  0.0093  0.0025  0.0044  0.0021   \n",
      "189  0.1923  ...  0.0223  0.0121  0.0108  0.0057  0.0028  0.0079  0.0034   \n",
      "190  0.1567  ...  0.0189  0.0150  0.0060  0.0082  0.0091  0.0038  0.0056   \n",
      "191  0.1533  ...  0.0138  0.0108  0.0062  0.0044  0.0072  0.0007  0.0054   \n",
      "192  0.1859  ...  0.0185  0.0072  0.0055  0.0074  0.0068  0.0084  0.0037   \n",
      "193  0.1747  ...  0.0209  0.0134  0.0094  0.0047  0.0045  0.0042  0.0028   \n",
      "194  0.2471  ...  0.0089  0.0083  0.0080  0.0026  0.0079  0.0042  0.0071   \n",
      "195  0.2245  ...  0.0204  0.0124  0.0093  0.0072  0.0019  0.0027  0.0054   \n",
      "196  0.2282  ...  0.0281  0.0165  0.0056  0.0010  0.0027  0.0062  0.0024   \n",
      "197  0.1847  ...  0.0166  0.0132  0.0027  0.0022  0.0059  0.0016  0.0025   \n",
      "198  0.2048  ...  0.0186  0.0096  0.0071  0.0084  0.0038  0.0026  0.0028   \n",
      "199  0.2271  ...  0.0202  0.0141  0.0103  0.0100  0.0034  0.0026  0.0037   \n",
      "200  0.3193  ...  0.0137  0.0150  0.0076  0.0032  0.0037  0.0071  0.0040   \n",
      "201  0.2660  ...  0.0130  0.0120  0.0039  0.0053  0.0062  0.0046  0.0045   \n",
      "202  0.3997  ...  0.0146  0.0091  0.0045  0.0043  0.0043  0.0098  0.0054   \n",
      "203  0.2684  ...  0.0203  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065   \n",
      "204  0.2154  ...  0.0051  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034   \n",
      "205  0.2529  ...  0.0155  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140   \n",
      "206  0.2354  ...  0.0042  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034   \n",
      "207  0.2354  ...  0.0181  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040   \n",
      "\n",
      "         57      58      59  \n",
      "0    0.0084  0.0090  0.0032  \n",
      "1    0.0049  0.0052  0.0044  \n",
      "2    0.0164  0.0095  0.0078  \n",
      "3    0.0044  0.0040  0.0117  \n",
      "4    0.0048  0.0107  0.0094  \n",
      "5    0.0027  0.0051  0.0062  \n",
      "6    0.0143  0.0036  0.0103  \n",
      "7    0.0047  0.0048  0.0053  \n",
      "8    0.0093  0.0059  0.0022  \n",
      "9    0.0035  0.0056  0.0040  \n",
      "10   0.0003  0.0053  0.0036  \n",
      "11   0.0092  0.0009  0.0044  \n",
      "12   0.0058  0.0059  0.0032  \n",
      "13   0.0053  0.0189  0.0102  \n",
      "14   0.0196  0.0147  0.0062  \n",
      "15   0.0049  0.0200  0.0073  \n",
      "16   0.0015  0.0073  0.0067  \n",
      "17   0.0037  0.0112  0.0075  \n",
      "18   0.0132  0.0070  0.0088  \n",
      "19   0.0094  0.0116  0.0063  \n",
      "20   0.0082  0.0028  0.0027  \n",
      "21   0.0162  0.0109  0.0079  \n",
      "22   0.0160  0.0106  0.0134  \n",
      "23   0.0037  0.0070  0.0041  \n",
      "24   0.0160  0.0095  0.0011  \n",
      "25   0.0024  0.0057  0.0044  \n",
      "26   0.0019  0.0023  0.0062  \n",
      "27   0.0057  0.0032  0.0019  \n",
      "28   0.0020  0.0091  0.0058  \n",
      "29   0.0092  0.0052  0.0075  \n",
      "..      ...     ...     ...  \n",
      "178  0.0045  0.0047  0.0054  \n",
      "179  0.0068  0.0053  0.0087  \n",
      "180  0.0056  0.0067  0.0054  \n",
      "181  0.0021  0.0043  0.0017  \n",
      "182  0.0030  0.0031  0.0033  \n",
      "183  0.0036  0.0043  0.0018  \n",
      "184  0.0027  0.0055  0.0057  \n",
      "185  0.0051  0.0033  0.0058  \n",
      "186  0.0087  0.0070  0.0042  \n",
      "187  0.0086  0.0110  0.0052  \n",
      "188  0.0069  0.0060  0.0018  \n",
      "189  0.0046  0.0022  0.0021  \n",
      "190  0.0056  0.0048  0.0024  \n",
      "191  0.0035  0.0001  0.0055  \n",
      "192  0.0024  0.0034  0.0007  \n",
      "193  0.0036  0.0013  0.0016  \n",
      "194  0.0044  0.0022  0.0014  \n",
      "195  0.0017  0.0024  0.0029  \n",
      "196  0.0063  0.0017  0.0028  \n",
      "197  0.0017  0.0027  0.0027  \n",
      "198  0.0013  0.0035  0.0060  \n",
      "199  0.0044  0.0057  0.0035  \n",
      "200  0.0009  0.0015  0.0085  \n",
      "201  0.0022  0.0005  0.0031  \n",
      "202  0.0051  0.0065  0.0103  \n",
      "203  0.0115  0.0193  0.0157  \n",
      "204  0.0032  0.0062  0.0067  \n",
      "205  0.0138  0.0077  0.0031  \n",
      "206  0.0079  0.0036  0.0048  \n",
      "207  0.0036  0.0061  0.0115  \n",
      "\n",
      "[208 rows x 60 columns]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "X = df1\n",
    "print(X)\n",
    "Y = df_new[\"o\"].tolist()\n",
    "print(Y)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, random_state=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(176.21052631578948, 205.35999999999999, 'X[10] <= 0.171\\nentropy = 0.5\\nsamples = 166\\nvalue = [84, 82]'),\n",
       " Text(88.10526315789474, 181.2, 'X[3] <= 0.052\\nentropy = 0.296\\nsamples = 61\\nvalue = [50, 11]'),\n",
       " Text(35.242105263157896, 157.04, 'X[17] <= 0.809\\nentropy = 0.08\\nsamples = 48\\nvalue = [46, 2]'),\n",
       " Text(17.621052631578948, 132.88, 'entropy = 0.0\\nsamples = 45\\nvalue = [45, 0]'),\n",
       " Text(52.863157894736844, 132.88, 'X[4] <= 0.068\\nentropy = 0.444\\nsamples = 3\\nvalue = [1, 2]'),\n",
       " Text(35.242105263157896, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(70.48421052631579, 108.72, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2]'),\n",
       " Text(140.96842105263158, 157.04, 'X[44] <= 0.162\\nentropy = 0.426\\nsamples = 13\\nvalue = [4, 9]'),\n",
       " Text(123.34736842105264, 132.88, 'X[45] <= 0.153\\nentropy = 0.32\\nsamples = 5\\nvalue = [4, 1]'),\n",
       " Text(105.72631578947369, 108.72, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0]'),\n",
       " Text(140.96842105263158, 108.72, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(158.58947368421053, 132.88, 'entropy = 0.0\\nsamples = 8\\nvalue = [0, 8]'),\n",
       " Text(264.3157894736842, 181.2, 'X[44] <= 0.264\\nentropy = 0.438\\nsamples = 105\\nvalue = [34, 71]'),\n",
       " Text(246.69473684210527, 157.04, 'X[35] <= 0.55\\nentropy = 0.487\\nsamples = 81\\nvalue = [34, 47]'),\n",
       " Text(229.07368421052632, 132.88, 'X[50] <= 0.012\\nentropy = 0.41\\nsamples = 66\\nvalue = [19, 47]'),\n",
       " Text(176.21052631578948, 108.72, 'X[51] <= 0.008\\nentropy = 0.494\\nsamples = 27\\nvalue = [15, 12]'),\n",
       " Text(158.58947368421053, 84.56, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0]'),\n",
       " Text(193.83157894736843, 84.56, 'X[32] <= 0.202\\nentropy = 0.444\\nsamples = 18\\nvalue = [6, 12]'),\n",
       " Text(176.21052631578948, 60.400000000000006, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0]'),\n",
       " Text(211.45263157894738, 60.400000000000006, 'X[42] <= 0.111\\nentropy = 0.32\\nsamples = 15\\nvalue = [3, 12]'),\n",
       " Text(193.83157894736843, 36.24000000000001, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(229.07368421052632, 36.24000000000001, 'X[48] <= 0.071\\nentropy = 0.142\\nsamples = 13\\nvalue = [1, 12]'),\n",
       " Text(211.45263157894738, 12.079999999999984, 'entropy = 0.0\\nsamples = 12\\nvalue = [0, 12]'),\n",
       " Text(246.69473684210527, 12.079999999999984, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(281.93684210526317, 108.72, 'X[18] <= 0.219\\nentropy = 0.184\\nsamples = 39\\nvalue = [4, 35]'),\n",
       " Text(264.3157894736842, 84.56, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(299.5578947368421, 84.56, 'X[41] <= 0.085\\nentropy = 0.102\\nsamples = 37\\nvalue = [2, 35]'),\n",
       " Text(281.93684210526317, 60.400000000000006, 'X[31] <= 0.251\\nentropy = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(264.3157894736842, 36.24000000000001, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(299.5578947368421, 36.24000000000001, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(317.17894736842106, 60.400000000000006, 'entropy = 0.0\\nsamples = 34\\nvalue = [0, 34]'),\n",
       " Text(264.3157894736842, 132.88, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0]'),\n",
       " Text(281.93684210526317, 157.04, 'entropy = 0.0\\nsamples = 24\\nvalue = [0, 24]')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "tree.plot_tree(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.10436445 0.01606659 0.\n",
      " 0.         0.         0.         0.         0.22863816 0.\n",
      " 0.         0.         0.         0.         0.         0.03012485\n",
      " 0.04091803 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01606659 0.03855981 0.         0.         0.1493733\n",
      " 0.         0.         0.         0.         0.         0.02952779\n",
      " 0.03559367 0.         0.12607401 0.01927991 0.         0.\n",
      " 0.02224605 0.         0.07890044 0.06426636 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "0.8333333333333334\n",
      "[1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0\n",
      " 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Visualization Graph\n",
    "dot_data = tree.export_graphviz(clf,out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"tree\")\n",
    "print(clf.feature_importances_)\n",
    "predicted = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,predicted))\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest classifier\n",
    "clf1 = RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01671943 0.01072387 0.02580855 0.06081194 0.01826626 0.0053568\n",
      " 0.         0.         0.067396   0.04006404 0.09448679 0.070761\n",
      " 0.04454517 0.0293612  0.         0.00667054 0.00882365 0.0055196\n",
      " 0.00609488 0.02186425 0.04776726 0.01605852 0.02347177 0.\n",
      " 0.         0.00682962 0.00846131 0.00937043 0.00243341 0.\n",
      " 0.00423098 0.         0.00076708 0.01063058 0.01081683 0.03105728\n",
      " 0.00990351 0.00479569 0.00970694 0.00219111 0.00611393 0.00976305\n",
      " 0.00544432 0.02359611 0.01956604 0.01283922 0.02035937 0.05060401\n",
      " 0.02769275 0.00091429 0.03515732 0.00838841 0.00817063 0.01318281\n",
      " 0.         0.00259643 0.00467036 0.01081718 0.00835747 0.        ]\n",
      "0.8571428571428571\n",
      "0.8855421686746988\n"
     ]
    }
   ],
   "source": [
    "print(clf1.feature_importances_)\n",
    "predicted = clf1.predict(X_test)\n",
    "Y_tpred1 = clf1.predict(X_train)\n",
    "print(accuracy_score(y_test,predicted))\n",
    "print(accuracy_score(y_train,Y_tpred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n",
      "0.8554216867469879\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Classification\n",
    "clf2 = svm.SVC(gamma='scale')\n",
    "clf2.fit(X_train,y_train)\n",
    "predicted = clf2.predict(X_test)\n",
    "Y_tpred2 = clf2.predict(X_train)\n",
    "print(accuracy_score(y_test,predicted))\n",
    "print(accuracy_score(y_train,Y_tpred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8809523809523809\n",
      "0.8674698795180723\n"
     ]
    }
   ],
   "source": [
    "clf_e= tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=60,max_depth=3,min_samples_leaf=5)\n",
    "clf_e = clf_e.fit(X_train,y_train)\n",
    "Ypred = clf_e.predict(X_test)\n",
    "Y_tpred3 = clf_e.predict(X_train)\n",
    "print(accuracy_score(y_test,Ypred))\n",
    "print(accuracy_score(y_train,Y_tpred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### K --- FOLD CROSS VALIDATION ON DECISION TREES #####\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "accuracy = []\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini', random_state = 42)\n",
    "clf_entropy = tree.DecisionTreeClassifier(criterion = 'entropy', random_state = 63)\n",
    "scores = cross_val_score(clf, X, Y, cv=kf)\n",
    "avg_score = np.mean(scores)\n",
    "print(avg_score)\n",
    "scores_en = cross_val_score(clf_entropy, X, Y, cv=kf)\n",
    "avg_score_en = np.mean(scores_en)\n",
    "print(scores)\n",
    "print(avg_score_en) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### K --- FOLD CROSS VALIDATION ON RANDOM FOREST #####\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "accuracy = []\n",
    "clf1 = RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)\n",
    "scores = cross_val_score(clf1, X, Y, cv=kf)\n",
    "avg_score = np.mean(scores)\n",
    "print(scores)\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### K --- FOLD CROSS VALIDATION ON SUPPORT VECTOR MACHINES #####\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "accuracy = []\n",
    "clf2 = svm.SVC(gamma='scale')\n",
    "scores = cross_val_score(clf2, X, Y, cv=kf)\n",
    "avg_score = np.mean(scores)\n",
    "print(scores)\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network --- Multi Layer Perceptron\n",
    "nn_mlp = MLPClassifier(hidden_layer_sizes=(24,), activation='logistic', solver='adam', alpha=0.0001,\n",
    "                    batch_size='auto', learning_rate='constant', learning_rate_init=0.001, \n",
    "                    power_t=0.5, max_iter=200, shuffle=True, random_state=40, tol=0.0001, \n",
    "                    verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                    epsilon=1e-08, n_iter_no_change=10)\n",
    "nn_mlp.fit(X_train,y_train)\n",
    "predictions = nn_mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Confusion matrix on test samples\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting heat map of confusion matrix -- dependency of different variables \n",
    "# Note to view completely please click on the image \n",
    "# if want to know the test dataset kindly convert it into a array and \n",
    "#put the index out there in # pd.DataFrame command.\n",
    "# Execution takes time so if you want to view just reduce the range. \n",
    "# Mentioned at last to avoid the time delay in running the entire code.\n",
    "# df_cm = pd.DataFrame(df_new, range(209), range(62))\n",
    "# plt.figure(figsize = (100,50))\n",
    "# sn.set(font_scale=2)\n",
    "# sn.heatmap(df_cm, annot=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### IMPLEMENTATION OF SEARCH FOR HYPERPARAMETER TUNING #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################... NOTES ... #########################################\n",
    "''' \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
